# Wizard-Tech | Emotion (Facial Emotion Detector)
# üôÇüòÄüòÆüòíüòîüò®   This is `Ongoing Project`, so I suggested issues. plz tell me if you have any ideas.


https://user-images.githubusercontent.com/96725900/164004710-2fbaaa02-fe4f-4645-b08d-d1426139ced5.mp4

![7Emotions](https://user-images.githubusercontent.com/96725900/163942354-e7befdcc-1772-4877-b271-bab3d5c9eabf.png)

![Emotion-AI](static/home.png)

Jump over to the Installation section using the table of contents if you don't want to know much about the project. 

<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href="#Description">Description</a></li>
    <li>
      <a href="#About the Models">About the Models</a>
      <ul>
        <li><a href="#Face Detector">Face Detector</a></li>
      </ul>
      <ul>
        <li><a href="#Facial Emotion Classifier">Facial Emotion Classifier</a></li>
      </ul>
      <ul>
        <li><a href="#Speech Transcriptor">Speech Transcriptor</a></li>
      </ul>
      <ul>
        <li><a href="#Voice Tonality Classifier">Voice Tonality Classifier</a></li>
      </ul>
      <ul>
        <li><a href="#Eye Gazing identifier">Eye Gazing identifier</a></li>
      </ul>
      <ul>
        <li><a href="#Biological Model">Biological Model</a></li>
      </ul>
      <ul>
        <li><a href="#How it works">How it works</a></li>
      </ul>
    </li>
    <li>
      <a href="#Installation">Installation</a>
      <ul>
        <li><a href="#Requirements">Requirements</a></li>
        <li><a href="#Setup">Setup</a></li>
      </ul>
    </li>
    <li><a href="#Inference">Inference</a></li>
    <li><a href="#License">License</a></li>
    <li><a href="#Credits">Credits</a></li>
  </ol>
</details>

# üìùDescription

Facial Emotion Detection is one of the useful and toughest Machine Learning tasks because of the intra-class variation in expressions among the people. The best usecase of FED is in human-machine interaction. Emotion-AI is a emotion(face, speech, eye gaze, brainwave) detection system  built using TensorFlow, which takes image input and display one of the seven emotions(Neutral, Happy, Surprise, Angry, Disgust, Sad, Fear).

<p align="right">(<a href="#top">back to top</a>)</p>

# ü§ñAbout the Models

The system employs several models: one for face detection and another for facial emotion classification. Then ...

## Face Detector

* Face detection model is built using TensorFlow 2.0 object detection API, where I used SSD MOBILENET V2 as the pretrained model.
* To built a face detection model first get the data(There will be many resources out there or else take some random pictures from internet and the number is dependent, in my case it's 50 for training and 10 for validation) to train the model.
* And then follow [this](https://tensorflow-object-detection-api-tutorial.readthedocs.io/) documentation to train a face detector on the gathered data. If u want a video tutorial check [this](https://youtu.be/XoMiveY_1Z4).
* I'd used colab to train the model.

## Facial Emotion Classifier

* Facial Emotion Classification model is built using TensorFlow 2.0, where I trained a deep convolutional neural network on RAF-DB. It's a generalised modelwith a training accuracy of 90% and test accuracy of 83%.
*  I'll create a separate repo on how to create a model like this, so if you're here then check my repos.
*  RAF-DB is a private database and to download it you need to send an email as shown on their [website](http://www.whdeng.cn/raf/model1.html#:~:text=Real%2Dworld%20Affective%20Faces%20Database%20(RAF%2DDB)%20is,labeled%20by%20about%2040%20annotators.).
*  First I'd started training the model on my local machine(GPU - GTX 1660ti), but when I started incresing the complexity of the model it took a lot of time to train and also started crying like a baby. 
*  I can't experiment fastly, So I shifted to kaggle to train the model. I've choosen kaggle over colab because of it's more gpu time and resources and it made experimentation faster.

## How it works

The input image is first given to the face detector to detect the face and then this is given to the facial emotion classifier to classify the emotion.

<p align="right">(<a href="#top">back to top</a>)</p>

# üñ•Installation

## üõ†Requirements

* Python 3.7+ 
* Other requirement are mentioned in requirements.txt and can be installed as shown below.

## ‚öôÔ∏èSetup
1. First create a virtual environment using venv. You can use powershell, go to the path you want and type the below commands. 
```
python -m venv Emotion
```
2. Activate it.
```
Emotion\Scripts\activate
```
Then you can use pip list to see what are all the packages installed and there will be pip and settup tools(in my case).

3. Upgrade pip to the latest version.
```
python -m pip install --upgrade pip
```
Clone the EmoViz repo and change the directory to EmoViz and run the below command.

4. Install the required packages.
```
python -m pip install -r requirements.txt
```
That's it you're set to go.

<p align="right">(<a href="#top">back to top</a>)</p>

# üéØInference
```
python app.py
```
<p align="right">(<a href="#top">back to top</a>)</p>

# ‚öñLicense
Distributed under the MIT License. See LICENSE.txt for more information.

<p align="right">(<a href="#top">back to top</a>)</p>

# Credits
* http://www.whdeng.cn/raf/li_RAFDB_2017_CVPR.pdf
* Vidusha, Alex Hong

<p align="right">(<a href="#top">back to top</a>)</p>
